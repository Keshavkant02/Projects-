{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keshavkant02/Projects-/blob/main/GBM_Differential_Expression_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHKVMhA6Pnxy"
      },
      "source": [
        "# GBM Differential Expression Analysis\n",
        "**Project Goal:** To perform differential expression analysis between GTEx brain samples and TCGA GBM samples to identify potential therapeutic targets and relevant biological pathways.\n",
        "**Data Sources:** GTEx Portal and TCGA GDC.\n",
        "**Key Steps:** Data Acquisition, Preprocessing, Normalization, Batch Correction (if needed), Differential Expression Analysis, GO Enrichment Analysis, Interpretation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "asiJLCCXcpHQ"
      },
      "outputs": [],
      "source": [
        "# Install required Python packages (run this cell once)\n",
        "!pip install pandas numpy matplotlib seaborn rpy2 biopython\n",
        "\n",
        "# Install required Bioconductor packages using Rscript and BiocManager\n",
        "!Rscript -e \"if (!requireNamespace('BiocManager', quietly=TRUE)) install.packages('BiocManager'); BiocManager::install('sva')\"\n",
        "!Rscript -e \"if (!requireNamespace('BiocManager', quietly=TRUE)) install.packages('BiocManager'); BiocManager::install('DESeq2')\"\n",
        "!Rscript -e \"if (!requireNamespace('BiocManager', quietly=TRUE)) install.packages('BiocManager'); BiocManager::install('clusterProfiler')\"\n",
        "!Rscript -e \"if (!requireNamespace('BiocManager', quietly=TRUE)) install.packages('BiocManager'); BiocManager::install('limma')\"\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from Bio import Entrez\n",
        "\n",
        "# Import rpy2 components to interface with R\n",
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects.packages import importr, PackageNotInstalledError\n",
        "from rpy2.robjects import pandas2ri\n",
        "\n",
        "# Activate automatic conversion between pandas and R data frames\n",
        "pandas2ri.activate()\n",
        "\n",
        "# Define a helper function to import an R package, with a helpful error if it's not installed\n",
        "def import_or_install(package_name):\n",
        "    try:\n",
        "        return importr(package_name)\n",
        "    except PackageNotInstalledError:\n",
        "        raise PackageNotInstalledError(\n",
        "            f\"The R package '{package_name}' is not installed. \"\n",
        "            f\"Please install it manually using BiocManager, e.g.: \\n\"\n",
        "            f\"!Rscript -e \\\"if (!requireNamespace('BiocManager', quietly=TRUE)) install.packages('BiocManager'); BiocManager::install('{package_name}')\\\"\"\n",
        "        )\n",
        "\n",
        "# Import core R libraries using our helper function\n",
        "base = importr('base')\n",
        "utils = importr('utils')\n",
        "\n",
        "deseq2 = import_or_install('DESeq2')\n",
        "clusterProfiler = import_or_install('clusterProfiler')\n",
        "sva = import_or_install('sva')\n",
        "limma = import_or_install('limma')\n",
        "\n",
        "print(\"Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9Nn5gAARTQc"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Create a directory to store uploaded files (optional)\n",
        "os.makedirs('gtex_data', exist_ok=True)\n",
        "\n",
        "# Upload all 40 CSV files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move files to the directory (if needed)\n",
        "for file_name in uploaded.keys():\n",
        "    os.rename(file_name, os.path.join('gtex_data', file_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgfB9gRnA5nZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load all CSV files and combine them into one DataFrame\n",
        "all_files = [f\"gtex_data/gtexsample_{i}.csv\" for i in range(1, 41)]  # Adjust if filenames differ\n",
        "dfs = []\n",
        "\n",
        "for file in all_files:\n",
        "    df = pd.read_csv(file, index_col=0)  # Use 'Name' (ENSG IDs) as index\n",
        "    df = df.drop(columns=['Description'])  # Remove non-numeric column\n",
        "    sample_name = df.columns[0]  # Assume each file has one sample column (e.g., GTEX-1117F-...)\n",
        "    df = df.rename(columns={sample_name: sample_name})  # Keep sample name as column\n",
        "    dfs.append(df)\n",
        "\n",
        "# Combine all DataFrames horizontally (samples as columns)\n",
        "gtex_df = pd.concat(dfs, axis=1)\n",
        "\n",
        "print(\"Combined DataFrame shape:\", gtex_df.shape)\n",
        "gtex_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfNVlTzQBKxH"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Transpose to samples Ã— genes\n",
        "pca_input = gtex_df.T.select_dtypes(include=[np.number])\n",
        "\n",
        "# Standardize and run PCA\n",
        "scaler = StandardScaler()\n",
        "pca_input_scaled = scaler.fit_transform(pca_input)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(pca_input_scaled)\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7)\n",
        "plt.title(\"PCA of GTEx Samples (Scaled)\")\n",
        "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.2%})\")\n",
        "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.2%})\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03nAAaR3jp8_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Create the 'gtex_data' directory if it doesn't exist\n",
        "os.makedirs('gtex_data', exist_ok=True)\n",
        "\n",
        "# 2. Assuming 'gtex_df' is your DataFrame after PCA:\n",
        "# Split the combined DataFrame back into individual sample DataFrames\n",
        "individual_dfs = [gtex_df[[col]] for col in gtex_df.columns]\n",
        "\n",
        "# 3. Iterate through the individual DataFrames and save them as CSV files:\n",
        "for i, df in enumerate(individual_dfs):\n",
        "    file_path = os.path.join('gtex_data', f'gtexsample_{i+1}.csv')\n",
        "    df.to_csv(file_path, index=True)  # Save with index (gene names)\n",
        "\n",
        "# 4. Save the correctly oriented gtex_df to 'combined_gtex.csv'\n",
        "gtex_df.to_csv(os.path.join('gtex_data', 'combined_gtex.csv'), index=True)\n",
        "\n",
        "print(\"Individual CSV files and combined_gtex.csv regenerated in 'gtex_data' directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnoCal4Nu8Jj"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thwyCSYVBYzG"
      },
      "outputs": [],
      "source": [
        "# 1. Import libraries\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# 2. Upload the file from your local machine\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 3. Get the uploaded filename\n",
        "#    (If you uploaded exactly one file, this grabs its name automatically)\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded file: {filename}\")\n",
        "\n",
        "# 4. Read the file into a pandas DataFrame\n",
        "#    - For a standard CSV, you can use the default sep=','\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "# 5. If your first column is 'gene_name' and you want it as the DataFrame index, do:\n",
        "# df.set_index('gene_name', inplace=True)\n",
        "\n",
        "# 6. Preview the first few rows\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4O215cZerK_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rpy2.robjects import r, pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "from rpy2.robjects.packages import importr\n",
        "\n",
        "# Install DESeq2 (if not already installed)\n",
        "utils = importr('utils')\n",
        "utils.install_packages('BiocManager')  # Install BiocManager if needed\n",
        "utils.install_packages('DESeq2', repos='https://cloud.r-project.org') # Install DESeq2\n",
        "\n",
        "\n",
        "# 1. Define paths to input files\n",
        "# ... (rest of your code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myLbhnNpbOJ4"
      },
      "outputs": [],
      "source": [
        "!pip install mygene\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wdQ1O-CxajW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mygene\n",
        "from rpy2.robjects import r, pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "\n",
        "###############################################\n",
        "# 1. Load GTEx Data by Combining 40 CSV Files\n",
        "###############################################\n",
        "def load_gtex_data():\n",
        "    folder = \"gtex_data\"  # Folder containing gtexsample_*.csv files\n",
        "    files = [os.path.join(folder, f\"gtexsample_{i}.csv\") for i in range(1, 41)]\n",
        "    dfs = []\n",
        "    for file in files:\n",
        "        try:\n",
        "            df = pd.read_csv(file, index_col=0)  # Assume first column (Ensembl IDs) is the index\n",
        "            # Drop non-numeric 'Description' column if present\n",
        "            if \"Description\" in df.columns:\n",
        "                df = df.drop(columns=[\"Description\"])\n",
        "            dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file}: {e}\")\n",
        "    combined = pd.concat(dfs, axis=1)\n",
        "    print(\"Combined GTEx DataFrame shape:\", combined.shape)\n",
        "    return combined\n",
        "\n",
        "###############################################\n",
        "# 2. Load Tumor Data\n",
        "###############################################\n",
        "def load_tumor_data():\n",
        "    tumor_file = \"subset_tumor.csv\"  # Your tumor CSV file\n",
        "    try:\n",
        "        tumor_df = pd.read_csv(tumor_file, index_col=0)\n",
        "        print(\"Tumor data loaded successfully. Shape:\", tumor_df.shape)\n",
        "    except Exception as e:\n",
        "        print(\"Error loading Tumor file:\", e)\n",
        "        raise e\n",
        "    return tumor_df\n",
        "\n",
        "###############################################\n",
        "# 3. Convert Tumor Gene Symbols to Ensembl IDs\n",
        "###############################################\n",
        "def convert_gene_to_ensembl(tumor_df):\n",
        "    \"\"\"\n",
        "    Converts the tumor DataFrame index (gene symbols) to Ensembl IDs using mygene.\n",
        "    \"\"\"\n",
        "    mg = mygene.MyGeneInfo()\n",
        "    gene_symbols = list(tumor_df.index.unique())\n",
        "    print(\"Converting\", len(gene_symbols), \"gene symbols to Ensembl IDs...\")\n",
        "    query_results = mg.querymany(gene_symbols, scopes=\"symbol\", fields=\"ensembl\", species=\"human\")\n",
        "    mapping_dict = {}\n",
        "    for result in query_results:\n",
        "        if \"ensembl\" in result:\n",
        "            ens = result[\"ensembl\"]\n",
        "            # If ensembl is a list, pick the first element and check for 'gene'\n",
        "            if isinstance(ens, list):\n",
        "                if \"gene\" in ens[0]:\n",
        "                    mapping_dict[result[\"query\"]] = ens[0][\"gene\"]\n",
        "            # If it's a dict, use its 'gene' key\n",
        "            elif isinstance(ens, dict):\n",
        "                if \"gene\" in ens:\n",
        "                    mapping_dict[result[\"query\"]] = ens[\"gene\"]\n",
        "    print(\"Mapping dictionary created with\", len(mapping_dict), \"entries.\")\n",
        "    # Map the tumor DataFrame index (gene symbol) to Ensembl ID.\n",
        "    tumor_df[\"ensembl_id\"] = tumor_df.index.map(lambda x: mapping_dict.get(x, None))\n",
        "    # Drop rows where conversion failed.\n",
        "    tumor_df = tumor_df.dropna(subset=[\"ensembl_id\"]).copy()\n",
        "    tumor_df = tumor_df.set_index(\"ensembl_id\")\n",
        "    return tumor_df\n",
        "\n",
        "###############################################\n",
        "# 4. Ensure Proper Orientation and Numeric Counts\n",
        "###############################################\n",
        "def ensure_orientation_and_numeric(df):\n",
        "    # Convert every entry to numeric; non-numeric become NaN, then fill with 0 and convert to int.\n",
        "    df_numeric = df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
        "    # If there are more columns than rows, assume the DataFrame is transposed.\n",
        "    if df_numeric.shape[0] < df_numeric.shape[1]:\n",
        "        print(\"Transposing DataFrame to ensure rows are genes and columns are samples.\")\n",
        "        df_numeric = df_numeric.T\n",
        "    return df_numeric\n",
        "\n",
        "###############################################\n",
        "# 5. Remove Version Numbers from GTEx Ensembl IDs\n",
        "###############################################\n",
        "def remove_version_from_index(df):\n",
        "    def remove_version(x):\n",
        "        return x.split('.')[0]\n",
        "    df.index = df.index.map(remove_version)\n",
        "    return df\n",
        "\n",
        "###############################################\n",
        "# 6. Aggregate Duplicate Genes\n",
        "###############################################\n",
        "def aggregate_duplicates(df):\n",
        "    if not df.index.is_unique:\n",
        "        print(f\"Aggregating duplicate gene entries. Original shape: {df.shape}\")\n",
        "        df = df.groupby(df.index).mean()\n",
        "        print(f\"New shape after aggregation: {df.shape}\")\n",
        "    return df\n",
        "\n",
        "###############################################\n",
        "# 7. Combine Data Based on Common Genes\n",
        "###############################################\n",
        "def combine_data(gtex_df, tumor_df):\n",
        "    common_genes = gtex_df.index.intersection(tumor_df.index)\n",
        "    print(f\"Found {len(common_genes)} common genes between GTEx and tumor data.\")\n",
        "    gtex_filtered = gtex_df.loc[common_genes]\n",
        "    tumor_filtered = tumor_df.loc[common_genes]\n",
        "    combined_df = pd.concat([gtex_filtered, tumor_filtered], axis=1)\n",
        "    return combined_df\n",
        "\n",
        "###############################################\n",
        "# 8. Normalize Combined Data Using DESeq2 via rpy2\n",
        "###############################################\n",
        "def normalize_with_deseq2(counts_df):\n",
        "    # Convert the pandas DataFrame to an R data frame.\n",
        "    with localconverter(pandas2ri.converter):\n",
        "        r_counts = pandas2ri.py2rpy(counts_df)\n",
        "\n",
        "    # Define the DESeq2 normalization function in R.\n",
        "    r('''\n",
        "library(DESeq2)\n",
        "perform_deseq2_normalization <- function(count_data) {\n",
        "    # Create a sample table (all samples are treated as \"control\" for normalization)\n",
        "    colData <- data.frame(condition = rep(\"control\", ncol(count_data)))\n",
        "    rownames(colData) <- colnames(count_data)\n",
        "\n",
        "    # Ensure counts are integers by rounding\n",
        "    count_data <- round(count_data)\n",
        "\n",
        "    # Create DESeqDataSet object with a simple design (~1)\n",
        "    dds <- DESeqDataSetFromMatrix(countData = count_data,\n",
        "                                  colData = colData,\n",
        "                                  design = ~ 1)\n",
        "    dds <- DESeq(dds)\n",
        "\n",
        "    # Get normalized counts\n",
        "    normCounts <- counts(dds, normalized = TRUE)\n",
        "    return(normCounts)\n",
        "}\n",
        "''')\n",
        "    # Call the R function.\n",
        "    normalized_r = r['perform_deseq2_normalization'](r_counts)\n",
        "\n",
        "    # Convert the result to an R data frame first.\n",
        "    normalized_r_df = r['as.data.frame'](normalized_r)\n",
        "\n",
        "    # Then convert the R data frame to a pandas DataFrame.\n",
        "    with localconverter(pandas2ri.converter):\n",
        "        normalized_df = pandas2ri.rpy2py(normalized_r_df)\n",
        "\n",
        "    return normalized_df\n",
        "\n",
        "###############################################\n",
        "# 9. Main Function\n",
        "###############################################\n",
        "def main():\n",
        "    # Load data\n",
        "    gtex_df = load_gtex_data()\n",
        "    tumor_df = load_tumor_data()\n",
        "\n",
        "    # Remove version numbers from GTEx IDs\n",
        "    gtex_df = remove_version_from_index(gtex_df)\n",
        "\n",
        "    # Convert tumor gene symbols to Ensembl IDs\n",
        "    tumor_df = convert_gene_to_ensembl(tumor_df)\n",
        "\n",
        "    # Ensure both datasets have proper orientation and numeric counts\n",
        "    gtex_df = ensure_orientation_and_numeric(gtex_df)\n",
        "    tumor_df = ensure_orientation_and_numeric(tumor_df)\n",
        "\n",
        "    # Aggregate duplicate gene entries\n",
        "    gtex_df = aggregate_duplicates(gtex_df)\n",
        "    tumor_df = aggregate_duplicates(tumor_df)\n",
        "\n",
        "    # Combine datasets on common Ensembl IDs\n",
        "    combined_df = combine_data(gtex_df, tumor_df)\n",
        "    print(\"Combined count matrix shape:\", combined_df.shape)\n",
        "\n",
        "    if combined_df.shape[0] == 0:\n",
        "        print(\"No common genes found! Check gene identifier conversion.\")\n",
        "        return\n",
        "\n",
        "    # Normalize combined data using DESeq2\n",
        "    normalized_df = normalize_with_deseq2(combined_df)\n",
        "    print(\"Normalization complete. Normalized data shape:\", normalized_df.shape)\n",
        "\n",
        "    # Save normalized counts to CSV\n",
        "    normalized_df.to_csv(\"normalized_counts.csv\", index=True)\n",
        "    print(\"Normalized counts saved to normalized_counts.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_sWBXI42nz2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from rpy2.robjects import r, pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load Normalized Counts Data\n",
        "# ---------------------------\n",
        "# This is the output from your DESeq2 normalization step.\n",
        "normalized_df = pd.read_csv(\"normalized_counts.csv\", index_col=0)\n",
        "print(\"Normalized counts shape:\", normalized_df.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Load Original GTEx and Tumor Data for Sample Info\n",
        "# ---------------------------\n",
        "gtex_file = os.path.join(\"gtex_data\", \"combined_gtex.csv\")\n",
        "tumor_file = \"subset_tumor.csv\"\n",
        "\n",
        "gtex_df = pd.read_csv(gtex_file, index_col=0)\n",
        "tumor_df = pd.read_csv(tumor_file, index_col=0)\n",
        "print(\"GTEx data shape:\", gtex_df.shape)\n",
        "print(\"Tumor data shape:\", tumor_df.shape)\n",
        "\n",
        "# Determine how many samples come from each group\n",
        "num_gtex = gtex_df.shape[1]\n",
        "num_tumor = tumor_df.shape[1]\n",
        "print(f\"Number of GTEx samples: {num_gtex}, Number of Tumor samples: {num_tumor}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Create Batch Vector\n",
        "# ---------------------------\n",
        "# Assuming the combined normalized matrix columns are ordered as GTEx samples first, then tumor.\n",
        "batch = np.array([0] * num_gtex + [1] * num_tumor)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. PCA Before Batch Correction\n",
        "# ---------------------------\n",
        "pca = PCA(n_components=2)\n",
        "# Transpose so that rows are samples and columns are genes\n",
        "pca_input = normalized_df.T.select_dtypes(include=[np.number])\n",
        "pca_result = pca.fit_transform(pca_input)\n",
        "pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'], index=pca_input.index)\n",
        "# Create a label for sample type based on batch\n",
        "pca_df['sample_type'] = ['GTEx' if b == 0 else 'Tumor' for b in batch]\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "for sample, color in zip(['GTEx', 'Tumor'], ['red', 'blue']):\n",
        "    indices = pca_df['sample_type'] == sample\n",
        "    plt.scatter(pca_df.loc[indices, 'PC1'], pca_df.loc[indices, 'PC2'],\n",
        "                c=color, label=sample, s=50)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA Before Batch Correction')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Batch Correction Using ComBat via rpy2\n",
        "# ---------------------------\n",
        "# Convert the normalized DataFrame to an R data frame.\n",
        "with localconverter(pandas2ri.converter):\n",
        "    r_norm = pandas2ri.py2rpy(normalized_df)\n",
        "\n",
        "# Define the ComBat batch correction function in R.\n",
        "r('''\n",
        "library(sva)\n",
        "perform_combat_batch_correction <- function(data, batch) {\n",
        "    mod <- model.matrix(~1, data = data.frame(batch))\n",
        "    combat_data <- ComBat(dat = data, batch = batch, mod = mod, par.prior=TRUE, ref.batch = NULL)\n",
        "    return(as.data.frame(combat_data))\n",
        "}\n",
        "''')\n",
        "\n",
        "# Convert the Python batch vector to an R vector.\n",
        "r_batch = robjects.FloatVector(batch)\n",
        "\n",
        "# Run ComBat batch correction.\n",
        "combat_corrected_r = r['perform_combat_batch_correction'](r_norm, r_batch)\n",
        "\n",
        "# Convert the corrected R data frame back to a pandas DataFrame.\n",
        "with localconverter(pandas2ri.converter):\n",
        "    combat_corrected_df = pandas2ri.rpy2py(combat_corrected_r)\n",
        "\n",
        "# ---------------------------\n",
        "# 6. PCA After Batch Correction\n",
        "# ---------------------------\n",
        "pca_after = PCA(n_components=2)\n",
        "pca_input_after = combat_corrected_df.T.select_dtypes(include=[np.number])\n",
        "pca_result_after = pca_after.fit_transform(pca_input_after)\n",
        "pca_df_after = pd.DataFrame(pca_result_after, columns=['PC1', 'PC2'], index=pca_input_after.index)\n",
        "pca_df_after['sample_type'] = ['GTEx' if b == 0 else 'Tumor' for b in batch]\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "for sample, color in zip(['GTEx', 'Tumor'], ['red', 'blue']):\n",
        "    indices = pca_df_after['sample_type'] == sample\n",
        "    plt.scatter(pca_df_after.loc[indices, 'PC1'], pca_df_after.loc[indices, 'PC2'],\n",
        "                c=color, label=sample, s=50)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA After Batch Correction')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Batch correction complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feJDFatJymqP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from rpy2.robjects import r, pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Create Sample Metadata for DE Analysis\n",
        "# ---------------------------\n",
        "# Assuming that your batch vector is defined as:\n",
        "#   batch = np.array([0]*num_gtex + [1]*num_tumor)\n",
        "# and that combat_corrected_df is your batch-corrected normalized counts DataFrame.\n",
        "# Also, assume that columns in combat_corrected_df are ordered such that\n",
        "# the first num_gtex columns correspond to GTEx (normal) and the next num_tumor columns correspond to Tumor.\n",
        "\n",
        "# Recreate your batch vector if needed (using the same numbers as before)\n",
        "# (Here, we assume these values are still available or recompute based on your data dimensions)\n",
        "num_gtex = gtex_df.shape[1]  # from your original GTEx combined data (before combining with tumor)\n",
        "num_tumor = tumor_df.shape[1]  # from your tumor file\n",
        "batch = [ \"GTEx\" ] * num_gtex + [ \"Tumor\" ] * num_tumor\n",
        "\n",
        "# Create a metadata DataFrame for samples (use column names from the corrected data)\n",
        "sample_names = combat_corrected_df.columns\n",
        "metadata_df = pd.DataFrame({'sample_type': batch}, index=sample_names)\n",
        "print(\"Sample metadata (first 5 rows):\")\n",
        "print(metadata_df.head())\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Convert Data to R Objects Using rpy2\n",
        "# ---------------------------\n",
        "with localconverter(pandas2ri.converter):\n",
        "    r_counts = pandas2ri.py2rpy(combat_corrected_df)\n",
        "    r_metadata = pandas2ri.py2rpy(metadata_df)\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Run Differential Expression Analysis in R using DESeq2 (with shifting)\n",
        "# ---------------------------\n",
        "# Define and run an R function to perform DESeq2 analysis.\n",
        "r('''\n",
        "library(DESeq2)\n",
        "run_deseq2 <- function(counts, colData) {\n",
        "    # Ensure that sample_type is a factor and set GTEx as the reference level.\n",
        "    colData$sample_type <- factor(colData$sample_type)\n",
        "    colData$sample_type <- relevel(colData$sample_type, ref = \"GTEx\")\n",
        "\n",
        "    # Shift counts if there are negative values\n",
        "    if(min(counts) < 0) {\n",
        "        counts <- counts - min(counts) + 1\n",
        "    }\n",
        "\n",
        "    # Create the DESeqDataSet object. (DESeq2 expects raw counts, so we round the input.)\n",
        "    dds <- DESeqDataSetFromMatrix(countData = round(counts),\n",
        "                                  colData = colData,\n",
        "                                  design = ~ sample_type)\n",
        "    dds <- DESeq(dds)\n",
        "\n",
        "    # Extract results: compare Tumor vs GTEx.\n",
        "    res <- results(dds, contrast=c(\"sample_type\", \"Tumor\", \"GTEx\"))\n",
        "    resOrdered <- res[order(res$padj), ]\n",
        "    return(as.data.frame(resOrdered))\n",
        "}\n",
        "''')\n",
        "\n",
        "# Run the function from Python.\n",
        "deseq2_results_r = r['run_deseq2'](r_counts, r_metadata)\n",
        "\n",
        "# Convert DESeq2 results back to a pandas DataFrame.\n",
        "with localconverter(pandas2ri.converter):\n",
        "    deseq2_results_df = pandas2ri.rpy2py(deseq2_results_r)\n",
        "\n",
        "print(\"Differential expression analysis complete. Results shape:\", deseq2_results_df.shape)\n",
        "print(\"Top DE genes:\")\n",
        "print(deseq2_results_df.head())\n",
        "\n",
        "# Save DESeq2 results to CSV.\n",
        "deseq2_results_df.to_csv(\"deseq2_results.csv\", index=True)\n",
        "print(\"DESeq2 results saved to 'deseq2_results.csv'\")\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Convert DESeq2 Results Back to a Pandas DataFrame\n",
        "# ---------------------------\n",
        "with localconverter(pandas2ri.converter):\n",
        "    deseq2_results_df = pandas2ri.rpy2py(deseq2_results_r)\n",
        "\n",
        "print(\"Differential expression analysis complete. Results shape:\", deseq2_results_df.shape)\n",
        "print(\"Top DE genes:\")\n",
        "print(deseq2_results_df.head())\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Save DESeq2 Results to CSV\n",
        "# ---------------------------\n",
        "deseq2_results_df.to_csv(\"deseq2_results.csv\", index=True)\n",
        "print(\"DESeq2 results saved to 'deseq2_results.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X-PWAom0zzb"
      },
      "outputs": [],
      "source": [
        "!Rscript -e \"if (!requireNamespace('BiocManager', quietly = TRUE)) install.packages('BiocManager'); BiocManager::install('org.Hs.eg.db')\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(deseq2_results.head())\n"
      ],
      "metadata": {
        "id": "tGjECWuTkBk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO4AUYHJ0bSV"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Required Libraries\n",
        "# ---------------------------\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mygene\n",
        "from rpy2.robjects import r, pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter, py2rpy, rpy2py # Import rpy2py explicitly\n",
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects.packages import importr\n",
        "\n",
        "# Install mygene if not already installed\n",
        "try:\n",
        "    import mygene\n",
        "except ImportError:\n",
        "    print(\"Installing mygene...\")\n",
        "    !pip install mygene --quiet\n",
        "    import mygene\n",
        "\n",
        "# Activate pandas DataFrame conversion for rpy2\n",
        "pandas2ri.activate()\n",
        "\n",
        "# ---------------------------\n",
        "# Configuration (MODIFY THESE)\n",
        "# ---------------------------\n",
        "deseq2_results_file = \"deseq2_results.csv\" # INPUT: Path to your DESeq2 results CSV\n",
        "output_prefix = \"enrichment_results\"       # Prefix for output PDF plot files\n",
        "go_output_csv = \"GO_enrichment_results.csv\"    # OUTPUT: GO results CSV\n",
        "kegg_output_csv = \"KEGG_enrichment_results.csv\"  # OUTPUT: KEGG results CSV\n",
        "\n",
        "padj_threshold = 0.05\n",
        "lfc_threshold = 1.0\n",
        "fallback_top_n_genes = 100 # Use top N genes if no significant genes found by thresholds\n",
        "target_species = \"human\"   # Or \"mouse\", etc. used by mygene\n",
        "kegg_organism_code = \"hsa\" # Human KEGG code. Change if species is different (e.g., \"mmu\" for mouse)\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load DESeq2 Results and Filter Genes\n",
        "# ---------------------------\n",
        "print(f\"Loading DESeq2 results from: {deseq2_results_file}\")\n",
        "try:\n",
        "    # Ensure the first column (gene IDs) is used as the index\n",
        "    deseq2_results = pd.read_csv(deseq2_results_file, index_col=0)\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: DESeq2 results file not found at {deseq2_results_file}\")\n",
        "    # --- Create dummy data if file not found (for testing) ---\n",
        "    print(\"Creating dummy DESeq2 results for demonstration...\")\n",
        "    genes = [f'GeneSymbol_{i}' for i in range(500)] + [f'ENSG{i:011d}' for i in range(500)]\n",
        "    dummy_data = {\n",
        "        'baseMean': np.random.rand(1000) * 1000,\n",
        "        'log2FoldChange': np.random.normal(0, 1.5, 1000),\n",
        "        'lfcSE': np.random.rand(1000) * 0.5,\n",
        "        'stat': np.random.normal(0, 3, 1000),\n",
        "        'pvalue': np.random.uniform(0, 1, 1000),\n",
        "        'padj': np.random.uniform(0, 1, 1000)\n",
        "    }\n",
        "    deseq2_results = pd.DataFrame(dummy_data, index=genes)\n",
        "    sig_idx = np.random.choice(deseq2_results.index, 150, replace=False)\n",
        "    deseq2_results.loc[sig_idx[:75], 'log2FoldChange'] = np.random.uniform(1.1, 3, 75)\n",
        "    deseq2_results.loc[sig_idx[75:], 'log2FoldChange'] = np.random.uniform(-3, -1.1, 75)\n",
        "    deseq2_results.loc[sig_idx, 'padj'] = np.random.uniform(0, 0.04, 150)\n",
        "    deseq2_results.loc[sig_idx, 'pvalue'] = np.random.uniform(0, 0.01, 150)\n",
        "    deseq2_results = deseq2_results.sort_values('pvalue')\n",
        "    # --- End dummy data ---\n",
        "\n",
        "print(\"DESeq2 results shape:\", deseq2_results.shape)\n",
        "\n",
        "# Filter for significant genes\n",
        "print(f\"\\nFiltering for significant genes (padj < {padj_threshold} & |log2FC| > {lfc_threshold})...\")\n",
        "sig_genes = deseq2_results[\n",
        "    (deseq2_results['padj'] < padj_threshold) &\n",
        "    (abs(deseq2_results['log2FoldChange']) > lfc_threshold)\n",
        "].copy() # Use copy to avoid SettingWithCopyWarning\n",
        "\n",
        "if sig_genes.empty:\n",
        "    print(f\"No significant DE genes found using strict criteria (padj < {padj_threshold}, |log2FC| > {lfc_threshold}).\")\n",
        "    print(f\"Selecting top {fallback_top_n_genes} genes by p-value as fallback.\")\n",
        "    sig_genes = deseq2_results.sort_values(\"pvalue\").head(fallback_top_n_genes).copy()\n",
        "    if sig_genes.empty:\n",
        "        raise ValueError(\"No genes found in DESeq2 results, even for fallback.\")\n",
        "\n",
        "print(f\"Number of genes selected for enrichment analysis: {sig_genes.shape[0]}\")\n",
        "if sig_genes.shape[0] < 10:\n",
        "     print(\"WARNING: Very few genes selected for enrichment. Results may not be meaningful.\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Check Gene Identifiers and Map If Needed (to Entrez IDs)\n",
        "# ---------------------------\n",
        "gene_list = list(sig_genes.index)\n",
        "print(\"\\nFirst 10 gene identifiers from results:\", gene_list[:10])\n",
        "\n",
        "try:\n",
        "    first_id_str = str(gene_list[0]).split(':')[-1]\n",
        "    _ = int(first_id_str)\n",
        "    are_entrez = True\n",
        "    print(\"Gene identifiers appear to be numeric (assuming Entrez IDs).\")\n",
        "    mapping_dict = {}\n",
        "    valid_entrez_count = 0\n",
        "    for gene in gene_list:\n",
        "       try:\n",
        "           entrez_id = int(str(gene).split(':')[-1])\n",
        "           mapping_dict[gene] = entrez_id\n",
        "           valid_entrez_count += 1\n",
        "       except ValueError:\n",
        "           print(f\"  Warning: Could not convert assumed Entrez ID '{gene}' to integer. Skipping.\")\n",
        "    print(f\"Successfully converted {valid_entrez_count} assumed Entrez IDs.\")\n",
        "\n",
        "except (ValueError, IndexError):\n",
        "    are_entrez = False\n",
        "    print(f\"Gene identifiers do not appear to be numeric Entrez IDs. Attempting mapping using MyGene.info for species '{target_species}'...\")\n",
        "    mg = mygene.MyGeneInfo()\n",
        "    query_results = mg.querymany(gene_list, scopes=\"symbol,alias,ensembl.gene\", fields=\"entrezgene\",\n",
        "                                 species=target_species, returnall=True, size=1000, verbose=False)\n",
        "\n",
        "    mapping_dict = {}\n",
        "    mapped_count = 0\n",
        "    unmapped_genes = []\n",
        "\n",
        "    for result in query_results.get('out', []):\n",
        "        query_gene = result.get('query')\n",
        "        entrez_id = result.get('entrezgene')\n",
        "        not_found = result.get('notfound', False)\n",
        "\n",
        "        if query_gene and entrez_id and not not_found:\n",
        "            if isinstance(entrez_id, list):\n",
        "                entrez_id = entrez_id[0]\n",
        "            try:\n",
        "               mapping_dict[query_gene] = int(entrez_id)\n",
        "               mapped_count += 1\n",
        "            except (ValueError, TypeError):\n",
        "               print(f\"  Warning: Found Entrez ID '{entrez_id}' for '{query_gene}', but couldn't convert to int. Skipping.\")\n",
        "        elif query_gene:\n",
        "            unmapped_genes.append(query_gene)\n",
        "\n",
        "    print(f\"Mapped {mapped_count} out of {len(gene_list)} genes to Entrez IDs.\")\n",
        "    if mapped_count == 0:\n",
        "        raise ValueError(\"No genes were mapped to Entrez IDs. Check input gene ID format, species, or enrichment thresholds.\")\n",
        "    if unmapped_genes:\n",
        "        print(f\"Could not map {len(unmapped_genes)} genes. First few unmapped: {unmapped_genes[:10]}\")\n",
        "\n",
        "sig_genes['entrez_id'] = sig_genes.index.map(mapping_dict.get)\n",
        "original_count = sig_genes.shape[0]\n",
        "sig_genes = sig_genes.dropna(subset=['entrez_id']).copy()\n",
        "sig_genes['entrez_id'] = sig_genes['entrez_id'].astype(int)\n",
        "dropped_count = original_count - sig_genes.shape[0]\n",
        "\n",
        "print(f\"Removed {dropped_count} genes that could not be mapped to Entrez IDs.\")\n",
        "print(f\"Final number of genes with Entrez IDs for enrichment: {sig_genes.shape[0]}\")\n",
        "\n",
        "if sig_genes.empty:\n",
        "    raise ValueError(\"No genes remaining after mapping to Entrez IDs. Cannot proceed with enrichment.\")\n",
        "\n",
        "entrez_ids = list(sig_genes['entrez_id'])\n",
        "r_entrez_ids = robjects.IntVector(entrez_ids)\n",
        "print(f\"First 10 Entrez IDs being passed to R: {entrez_ids[:10]}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Install/Load Required R Packages\n",
        "# ---------------------------\n",
        "print(\"\\nChecking/Installing required R packages...\")\n",
        "\n",
        "# Set the Python variable into the R global environment\n",
        "robjects.globalenv['target_species_r'] = robjects.StrVector([target_species])\n",
        "\n",
        "r('''\n",
        "install_if_missing <- function(pkg, repo=c(\"CRAN\", \"Bioconductor\")) {\n",
        "  repo <- match.arg(repo)\n",
        "  if (!requireNamespace(pkg, quietly = TRUE)) {\n",
        "    message(paste(\"Installing\", pkg, \"...\"))\n",
        "    if (repo == \"Bioconductor\") {\n",
        "      if (!requireNamespace(\"BiocManager\", quietly = TRUE)) {\n",
        "        install.packages(\"BiocManager\", quiet = TRUE, repos = \"https://cloud.r-project.org/\")\n",
        "      }\n",
        "      BiocManager::install(pkg, update=FALSE, ask=FALSE)\n",
        "    } else {\n",
        "      install.packages(pkg, quiet = TRUE, repos = \"https://cloud.r-project.org/\")\n",
        "    }\n",
        "  } else {\n",
        "    # message(paste(pkg, \"is already installed.\"))\n",
        "  }\n",
        "  # Load the library after ensuring installation\n",
        "  library(pkg, character.only = TRUE)\n",
        "}\n",
        "\n",
        "# Determine OrgDb package based on species\n",
        "get_orgdb_pkg <- function(species_lower) {\n",
        "    if (species_lower == 'human') {\n",
        "        return(\"org.Hs.eg.db\")\n",
        "    } else if (species_lower == 'mouse') {\n",
        "        return(\"org.Mm.eg.db\")\n",
        "    } # Add other organisms here, e.g.:\n",
        "    # else if (species_lower == 'rat') {\n",
        "    #     return(\"org.Rn.eg.db\")\n",
        "    # }\n",
        "      else {\n",
        "        stop(paste(\"Unsupported species for automatic OrgDb selection:\", species_lower))\n",
        "    }\n",
        "}\n",
        "\n",
        "# Get OrgDb package name from Python variable\n",
        "orgdb_package_name <- get_orgdb_pkg(tolower(target_species_r)) # Use variable passed from Python\n",
        "\n",
        "required_pkgs <- list()\n",
        "required_pkgs[[orgdb_package_name]] <- \"Bioconductor\"\n",
        "required_pkgs[[\"clusterProfiler\"]] <- \"Bioconductor\"\n",
        "\n",
        "# Loop through and install/load\n",
        "for (pkg_name in names(required_pkgs)) {\n",
        "  install_if_missing(pkg_name, repo = required_pkgs[[pkg_name]])\n",
        "}\n",
        "\n",
        "message(\"Required R packages checked/loaded.\")\n",
        "''')\n",
        "\n",
        "orgdb_package = r('orgdb_package_name')[0] # Get determined package name back from R\n",
        "print(f\"Using R OrgDb package: {orgdb_package}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Define and Run the Enrichment Analysis Function in R\n",
        "# ---------------------------\n",
        "print(\"\\nDefining and running enrichment analysis function in R...\")\n",
        "\n",
        "# Define the R function as a string\n",
        "r_enrichment_func_def = f'''\n",
        "# Ensure libraries are loaded in this environment\n",
        "library(clusterProfiler)\n",
        "library({orgdb_package}) # Load the correct organism database\n",
        "\n",
        "perform_enrichment <- function(entrez_ids, orgdb_pkg_name_arg, kegg_org_code, output_prefix) {{\n",
        "    # Convert to character for safety, especially KEGG\n",
        "    entrez_ids_char <- as.character(entrez_ids)\n",
        "    entrez_ids_num <- as.numeric(entrez_ids_char) # enrichGO often prefers numeric\n",
        "\n",
        "    message(\"Starting GO enrichment (Biological Process)...\")\n",
        "    go_bp <- NULL\n",
        "    tryCatch({{\n",
        "        go_bp <- enrichGO(\n",
        "          gene          = entrez_ids_num, # Use numeric for enrichGO\n",
        "          OrgDb         = get(orgdb_pkg_name_arg), # Use package name variable\n",
        "          keyType       = \"ENTREZID\",\n",
        "          ont           = \"BP\",\n",
        "          pAdjustMethod = \"BH\",\n",
        "          pvalueCutoff  = 0.05,\n",
        "          qvalueCutoff  = 0.20\n",
        "        )\n",
        "        message(\"GO enrichment completed.\")\n",
        "    }}, error = function(e) {{\n",
        "        message(\"GO enrichment failed: \", conditionMessage(e))\n",
        "    }})\n",
        "\n",
        "    go_df <- if (!is.null(go_bp) && nrow(as.data.frame(go_bp)) > 0) as.data.frame(go_bp) else {{message(\"No significant GO terms.\"); data.frame()}}\n",
        "\n",
        "    message(\"\\\\nStarting KEGG enrichment...\")\n",
        "    kegg <- NULL\n",
        "    tryCatch({{\n",
        "        kegg <- enrichKEGG(\n",
        "          gene          = entrez_ids_char, # Use character for KEGG\n",
        "          organism      = kegg_org_code,\n",
        "          pAdjustMethod = \"BH\",\n",
        "          pvalueCutoff  = 0.05,\n",
        "          qvalueCutoff  = 0.20\n",
        "        )\n",
        "        message(\"KEGG enrichment completed.\")\n",
        "    }}, error = function(e) {{\n",
        "        message(\"KEGG enrichment failed: \", conditionMessage(e))\n",
        "        if(grepl(\"HTTP error|download|URL\", conditionMessage(e), ignore.case = TRUE)) {{\n",
        "          message(\"  (This might be due to internet connection issues required for KEGG.)\")\n",
        "        }}\n",
        "    }})\n",
        "\n",
        "    kegg_df <- if (!is.null(kegg) && nrow(as.data.frame(kegg)) > 0) as.data.frame(kegg) else {{message(\"No significant KEGG pathways.\"); data.frame()}}\n",
        "\n",
        "    # Generate plots (saving to current directory)\n",
        "    if(!is.null(go_bp) && nrow(go_df) > 0) {{\n",
        "        tryCatch({{\n",
        "            go_plot_file <- paste0(output_prefix, \"_GO_dotplot.pdf\")\n",
        "            pdf(go_plot_file, width=12, height=max(8, min(25, nrow(go_df))*0.35)) # Adjust height, max 25 terms\n",
        "            print(dotplot(go_bp, showCategory=min(30, nrow(go_df)), title=\"GO Biological Process Enrichment\"))\n",
        "            dev.off()\n",
        "            message(paste(\"  GO dotplot saved to\", go_plot_file))\n",
        "        }}, error = function(e) {{ message(\"  Failed to create GO plot: \", conditionMessage(e)) }})\n",
        "    }}\n",
        "\n",
        "    if(!is.null(kegg) && nrow(kegg_df) > 0) {{\n",
        "         tryCatch({{\n",
        "            kegg_plot_file <- paste0(output_prefix, \"_KEGG_dotplot.pdf\")\n",
        "            pdf(kegg_plot_file, width=12, height=max(8, min(25, nrow(kegg_df))*0.35))\n",
        "            print(dotplot(kegg, showCategory=min(30, nrow(kegg_df)), title=\"KEGG Pathway Enrichment\"))\n",
        "            dev.off()\n",
        "            message(paste(\"  KEGG dotplot saved to\", kegg_plot_file))\n",
        "        }}, error = function(e) {{ message(\"  Failed to create KEGG plot: \", conditionMessage(e)) }})\n",
        "    }}\n",
        "\n",
        "    return(list(go_bp = go_df, kegg = kegg_df))\n",
        "}}\n",
        "'''\n",
        "\n",
        "# Execute the R code string to define the function in R's global environment\n",
        "r(r_enrichment_func_def)\n",
        "\n",
        "# Run the R function\n",
        "print(f\"\\nRunning R perform_enrichment function with {len(entrez_ids)} Entrez IDs...\")\n",
        "enrichment_results = r['perform_enrichment'](\n",
        "    r_entrez_ids,\n",
        "    robjects.StrVector([orgdb_package]), # Pass OrgDb name as string vector\n",
        "    robjects.StrVector([kegg_organism_code]), # Pass KEGG code as string vector\n",
        "    robjects.StrVector([output_prefix]) # Pass prefix as string vector\n",
        ")\n",
        "print(\"R function execution finished.\")\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Convert R Results Back to Pandas DataFrames\n",
        "# ---------------------------\n",
        "print(\"\\nConverting R results back to pandas DataFrames...\")\n",
        "\n",
        "# Access list elements from R\n",
        "r_go_result = enrichment_results.rx2('go_bp')\n",
        "r_kegg_result = enrichment_results.rx2('kegg')\n",
        "\n",
        "# Use default rpy2 conversion (handles data frames well)\n",
        "try:\n",
        "    go_bp_df = rpy2py(r_go_result) # Use imported rpy2py\n",
        "    kegg_df = rpy2py(r_kegg_result)\n",
        "\n",
        "    # Ensure they are DataFrames\n",
        "    if not isinstance(go_bp_df, pd.DataFrame):\n",
        "        go_bp_df = pd.DataFrame()\n",
        "    if not isinstance(kegg_df, pd.DataFrame):\n",
        "        kegg_df = pd.DataFrame()\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error during R-to-Python conversion:\", e)\n",
        "    print(\"Raw R GO result object type:\", type(r_go_result))\n",
        "    print(r_go_result)\n",
        "    print(\"\\nRaw R KEGG result object type:\", type(r_kegg_result))\n",
        "    print(r_kegg_result)\n",
        "    raise e\n",
        "\n",
        "print(\"\\n--- GO Enrichment Results ---\")\n",
        "if go_bp_df.empty:\n",
        "    print(\"No significant GO enrichment results found or returned.\")\n",
        "else:\n",
        "    go_bp_df = go_bp_df.sort_values(by='p.adjust')\n",
        "    print(go_bp_df.head())\n",
        "    go_bp_df.to_csv(go_output_csv, index=False)\n",
        "    print(f\"\\nGO results saved to {go_output_csv}\")\n",
        "\n",
        "print(\"\\n--- KEGG Enrichment Results ---\")\n",
        "if kegg_df.empty:\n",
        "    print(\"No significant KEGG enrichment results found or returned.\")\n",
        "else:\n",
        "    kegg_df = kegg_df.sort_values(by='p.adjust')\n",
        "    print(kegg_df.head())\n",
        "    kegg_df.to_csv(kegg_output_csv, index=False)\n",
        "    print(f\"\\nKEGG results saved to {kegg_output_csv}\")\n",
        "\n",
        "print(\"\\nEnrichment analysis complete. Check CSV files and PDF plots (if generated).\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUrQehyZrq+ST8Vn6sPFtH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}